{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to test the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from gymnasium.wrappers import GrayScaleObservation\n",
    "from gymnasium.wrappers import ResizeObservation\n",
    "from gymnasium.wrappers import FrameStack, RecordVideo\n",
    "from tensorflow import keras\n",
    "from collections import deque\n",
    "\n",
    "#np.random.seed(42)\n",
    "\n",
    "name = \"Freeway\"\n",
    "model_path = \"./Freeway-v5/best_run/policy/\"\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(f'ALE/{name}-v5',\n",
    "                frameskip=4,\n",
    "                render_mode=\"human\",\n",
    "                max_episode_steps=18000/4)\n",
    "\n",
    "#env = RecordVideo(env, f\"./videos/{name}\")\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, 84)\n",
    "env = FrameStack(env,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, state):\n",
    "    state = np.float32(state) / 255\n",
    "    actions_probs, _, _ = model.predict(state, verbose=0)\n",
    "    action = np.random.choice(np.arange(env.action_space.n), p=np.asarray(actions_probs.squeeze()))\n",
    "\n",
    "    next_state, reward, term, trunc, _,  = env.step(action)\n",
    "    #record_env.step(action)\n",
    "    next_state = np.expand_dims(next_state, axis=0)\n",
    "    next_state = np.expand_dims(next_state, axis=-1)\n",
    "    \n",
    "    return next_state, reward, term, trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 50\n",
    "mean_rwd = 0 \n",
    "\n",
    "state,_ = env.reset()\n",
    "#record_env.reset()\n",
    "#record_env.start_video_recorder()\n",
    "state = np.expand_dims(state, axis=0)\n",
    "state = np.expand_dims(state, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "while True:\n",
    "    state, reward, term, trunc = play_one_step(env, state)\n",
    "    mean_rwd = mean_rwd + 1/count * (reward - mean_rwd)\n",
    "    count += 1\n",
    "    #env.render()\n",
    "    if term or trunc:\n",
    "        break\n",
    "#record_env.close_video_recorder()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
